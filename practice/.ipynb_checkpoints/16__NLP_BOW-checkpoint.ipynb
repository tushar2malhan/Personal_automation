{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95899a62",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thor': 12,\n",
       " 'hathodawala': 2,\n",
       " 'is': 5,\n",
       " 'looking': 9,\n",
       " 'for': 0,\n",
       " 'job': 8,\n",
       " 'thor hathodawala': 13,\n",
       " 'hathodawala is': 3,\n",
       " 'is looking': 6,\n",
       " 'looking for': 10,\n",
       " 'for job': 1,\n",
       " 'thor hathodawala is': 14,\n",
       " 'hathodawala is looking': 4,\n",
       " 'is looking for': 7,\n",
       " 'looking for job': 11}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Codebasics - Bag of N grams tutorial\n",
    "# Ltes generate n-grams using CountVectorizer  == Vocabulary\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "v = CountVectorizer(ngram_range=(1,2))       # bi gram\n",
    "v = CountVectorizer(ngram_range=(1,3))       # tri grams\n",
    "v.fit([\"Thor Hathodawala is looking for a job\"])\n",
    "v.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cc9cf1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# load english language model and create nlp object from it\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "def preprocess(text):\n",
    "    # removed stop words , punctuations\n",
    "#     and lemmatize the text\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)  # LEMMA gives base word  | ate -> eat |\n",
    "    \n",
    "    return \" \".join(filtered_tokens) \n",
    "# dir(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "061bb876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thor eat pizza'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(\"Thor ate pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4361d1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Loki eat pizza'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(\"Loki is eating pizza\")\n",
    "# removed stop words and included lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3649ec5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thor eat pizza', 'Loki tall', 'Loki eat pizza']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\n",
    "    \"Thor ate pizza\",\n",
    "    \"Loki is tall\",\n",
    "    \"Loki is eating pizza\"\n",
    "]\n",
    "corpus_processed = [\n",
    "    preprocess(text) for text in corpus\n",
    "]\n",
    "corpus_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e21bf67",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thor': 7,\n",
       " 'eat': 0,\n",
       " 'pizza': 5,\n",
       " 'thor eat': 8,\n",
       " 'eat pizza': 1,\n",
       " 'loki': 2,\n",
       " 'tall': 6,\n",
       " 'loki tall': 4,\n",
       " 'loki eat': 3}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vocabulary created with bi-gram\n",
    "v = CountVectorizer(ngram_range=(1,2))\n",
    "v.fit(corpus_processed)\n",
    "v.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4df8189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From v.vocabulary_  we check which words are coming \n",
    "v.transform([\"Hulk eat pizza\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "315a938a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12695, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Watching SchrÃ¶dinger's Cat Die University of C...</td>\n",
       "      <td>SCIENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WATCH: Freaky Vortex Opens Up In Flooded Lake</td>\n",
       "      <td>SCIENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Entrepreneurs Today Don't Need a Big Budget to...</td>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>These Roads Could Recharge Your Electric Car A...</td>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Civilian 'Guard' Fires Gun While 'Protecting' ...</td>\n",
       "      <td>CRIME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  category\n",
       "0  Watching SchrÃ¶dinger's Cat Die University of C...   SCIENCE\n",
       "1     WATCH: Freaky Vortex Opens Up In Flooded Lake    SCIENCE\n",
       "2  Entrepreneurs Today Don't Need a Big Budget to...  BUSINESS\n",
       "3  These Roads Could Recharge Your Electric Car A...  BUSINESS\n",
       "4  Civilian 'Guard' Fires Gun While 'Protecting' ...     CRIME"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# News Category Classification Problem\n",
    "\n",
    "#  basics of BAG of n grams vectorizer ðŸ˜Ž \n",
    "# It is the time to work on a real problem\n",
    "# We will use bag of n-grams and traing a machine learning \n",
    "# model that can categorize any news into one of the following categories,\n",
    "\n",
    "\n",
    "# SO bussiness text == Input ,   Category == Output\n",
    "\n",
    "# BUSINESS     SPORTS      CRIME       SCIENCE     \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('NLP_news_dataset.json')\n",
    "print(df.shape)\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca68104f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BUSINESS    4254\n",
       "SPORTS      4167\n",
       "CRIME       2893\n",
       "SCIENCE     1381\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3ec1f50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BUSINESS    1381\n",
       "SPORTS      1381\n",
       "CRIME       1381\n",
       "SCIENCE     1381\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a simple technique of undersampling.\n",
    "\n",
    "min_samples = 1381 \n",
    "# we have these many SCIENCE articles and SCIENCE is our minority class\n",
    "# SO We will adjust other categories to adjust all 4 categories data in same shape\n",
    "\n",
    "\n",
    "df_business = df[df.category==\"BUSINESS\"].sample(min_samples, random_state=2022) \n",
    "df_sports = df[df.category==\"SPORTS\"].sample(min_samples, random_state=2022)\n",
    "df_crime = df[df.category==\"CRIME\"].sample(min_samples, random_state=2022)\n",
    "df_science = df[df.category==\"SCIENCE\"].sample(min_samples, random_state=2022)\n",
    "\n",
    "df_balanced = pd.concat([df_business,df_sports,df_crime,df_science],axis=0)\n",
    "df_balanced.category.value_counts()\n",
    "# df_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1d6f1a4d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>category_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11967</th>\n",
       "      <td>GCC Business Leaders Remain Confident in the F...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>From the Other Side; an Honest Review from Emp...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3408</th>\n",
       "      <td>Mike McDerment, CEO of FreshBooks, Talks About...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>How to Market Your Business While Traveling th...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>How to Leverage Intuition in Decision-making I...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  category  \\\n",
       "11967  GCC Business Leaders Remain Confident in the F...  BUSINESS   \n",
       "2912   From the Other Side; an Honest Review from Emp...  BUSINESS   \n",
       "3408   Mike McDerment, CEO of FreshBooks, Talks About...  BUSINESS   \n",
       "502    How to Market Your Business While Traveling th...  BUSINESS   \n",
       "5279   How to Leverage Intuition in Decision-making I...  BUSINESS   \n",
       "\n",
       "       category_number  \n",
       "11967                0  \n",
       "2912                 0  \n",
       "3408                 0  \n",
       "502                  0  \n",
       "5279                 0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets mark category in numeric terms where it defines each category since it cannot understand text\n",
    "\n",
    "# target = {'BUSINESS': 0, 'SPORTS': 1, 'CRIME': 2, 'SCIENCE': 3}\n",
    "\n",
    "# df_balanced['category_number'] = df_balanced['category'].map({\n",
    "#     'BUSINESS': 0,\n",
    "#     'SPORTS': 1, \n",
    "#     'CRIME': 2, \n",
    "#     'SCIENCE': 3\n",
    "# })\n",
    "# df_balanced\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# # df_balanced.head()\n",
    "le_bussiness_category = LabelEncoder()\n",
    "df_balanced['category_number'] = le_bussiness_category.fit_transform(df_balanced.category)\n",
    "# df_balanced.category.value_counts()\n",
    "df_balanced.head()\n",
    "\n",
    "#   'BUSINESS': 0,\n",
    "#     'CRIME': 1, \n",
    "#     'SCIENCE': 2\n",
    "#     'SPORTS': 3, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e49315f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SPORTS      1105\n",
       "SCIENCE     1105\n",
       "BUSINESS    1105\n",
       "CRIME       1104\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "df_balanced.text,\n",
    "df_balanced.category,\n",
    "test_size=0.2,\n",
    "random_state=2022,\n",
    "stratify=df_balanced.category_number\n",
    ")\n",
    "\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b90e6cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BUSINESS       0.65      0.91      0.76       276\n",
      "       CRIME       0.87      0.86      0.86       277\n",
      "     SCIENCE       0.92      0.70      0.79       276\n",
      "      SPORTS       0.91      0.76      0.83       276\n",
      "\n",
      "    accuracy                           0.81      1105\n",
      "   macro avg       0.84      0.81      0.81      1105\n",
      "weighted avg       0.84      0.81      0.81      1105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "#Since it is CountVectorizer , we can use Sklearn pipeline for this\n",
    "pipe_line =Pipeline(\n",
    "    [\n",
    "     ('vectorizer_bow', CountVectorizer(ngram_range = (1, 3))   ),        #using the ngram_range parameter \n",
    "     ('Multi NB', MultinomialNB())         \n",
    "    ]\n",
    ")\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "pipe_line.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = pipe_line.predict(X_test)\n",
    "\n",
    "y_pred\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# CHECKED with bi gram and trigram| ngram_range = (1, 2)| ngram_range = (1, 3) | , BOW wins overall here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a18b8686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BUSINESS', 'SPORTS', 'SPORTS', 'BUSINESS', 'SCIENCE'], dtype='<U8')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "47a21d1f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>category_number</th>\n",
       "      <th>preprocessed_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11967</th>\n",
       "      <td>GCC Business Leaders Remain Confident in the F...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "      <td>gcc Business leader remain Confident face Regi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>From the Other Side; an Honest Review from Emp...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "      <td>Honest Review employee wake morning love impor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3408</th>\n",
       "      <td>Mike McDerment, CEO of FreshBooks, Talks About...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "      <td>Mike McDerment ceo FreshBooks talk give build ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>How to Market Your Business While Traveling th...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "      <td>market business travel World recently amazing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>How to Leverage Intuition in Decision-making I...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "      <td>Leverage intuition decision making feel safe r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  category  \\\n",
       "11967  GCC Business Leaders Remain Confident in the F...  BUSINESS   \n",
       "2912   From the Other Side; an Honest Review from Emp...  BUSINESS   \n",
       "3408   Mike McDerment, CEO of FreshBooks, Talks About...  BUSINESS   \n",
       "502    How to Market Your Business While Traveling th...  BUSINESS   \n",
       "5279   How to Leverage Intuition in Decision-making I...  BUSINESS   \n",
       "\n",
       "       category_number                                   preprocessed_txt  \n",
       "11967                0  gcc Business leader remain Confident face Regi...  \n",
       "2912                 0  Honest Review employee wake morning love impor...  \n",
       "3408                 0  Mike McDerment ceo FreshBooks talk give build ...  \n",
       "502                  0  market business travel World recently amazing ...  \n",
       "5279                 0  Leverage intuition decision making feel safe r...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_balanced['preprocessed_txt'] = df.text.apply(preprocess)  # LEMMA AND PREPROCESS DONE FOR COLUMN TEXT \n",
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "51adf51a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BUSINESS       0.83      0.88      0.85       276\n",
      "       CRIME       0.87      0.91      0.89       277\n",
      "     SCIENCE       0.92      0.83      0.87       276\n",
      "      SPORTS       0.90      0.88      0.89       276\n",
      "\n",
      "    accuracy                           0.88      1105\n",
      "   macro avg       0.88      0.88      0.88      1105\n",
      "weighted avg       0.88      0.88      0.88      1105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#                                 BUILDING MODEL WITH PREPROCESSED TEXT \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_balanced.preprocessed_txt,\n",
    "    df_balanced.category,\n",
    "    test_size = 0.2,\n",
    "    random_state=2022,\n",
    "    stratify=df_balanced.category_number\n",
    ")\n",
    "\n",
    "# y_train.value_counts()\n",
    "# PIPE LINE OBJECT on PREPROCESS DATA \n",
    "\n",
    "clf = Pipeline(\n",
    "    [\n",
    "        ('countvectorizer',CountVectorizer()), # CountVectorizer(ngram_range = (1, 1))\n",
    "        ('Multi', MultinomialNB())\n",
    "    ]\n",
    ")\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# If you compare above classification report for (1,2)\n",
    "# gram with the one from unprocessed text, you will find\n",
    "# some improvement in the model that uses preprocessed\n",
    "# cleaned up text. Hence we can conclude that for this\n",
    "# particular problem using preprocessing\n",
    "# (removing stop words, lemmatization) \n",
    "# is improving the performance of the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bfaa929b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[243,  14,  10,   9],\n",
       "       [ 10, 252,   5,  10],\n",
       "       [ 30,   9, 230,   7],\n",
       "       [ 11,  15,   6, 244]], dtype=int64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3292f133",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                        Fake News Detection                ==>    EXERCISE\n",
    "\n",
    "# This data consists of two columns. - Text - label\n",
    "\n",
    "# Text is the statements or messages regarding a particular event/situation.\n",
    "\n",
    "# label feature tells whether the given Text is Fake or Real.\n",
    "\n",
    "# As there are only 2 classes, this problem comes under the Binary Classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9247babe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top Trump Surrogate BRUTALLY Stabs Him In The...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. conservative leader optimistic of common ...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump proposes U.S. tax overhaul, stirs concer...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Court Forces Ohio To Allow Millions Of Illega...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrats say Trump agrees to work on immigrat...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text label\n",
       "0   Top Trump Surrogate BRUTALLY Stabs Him In The...  Fake\n",
       "1  U.S. conservative leader optimistic of common ...  Real\n",
       "2  Trump proposes U.S. tax overhaul, stirs concer...  Real\n",
       "3   Court Forces Ohio To Allow Millions Of Illega...  Fake\n",
       "4  Democrats say Trump agrees to work on immigrat...  Real"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Fake_Real_Data NLP__16.csv')\n",
    "df.head()\n",
    "# df.label.value_counts()  # --> distribution of labels  # our input output are matched perfectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb49f27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre processing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lable = LabelEncoder()\n",
    "df['label_number'] = lable.fit_transform(df['label'])\n",
    "# df.label.value_counts()                               #  thus same as df.label\n",
    "\n",
    "df['preprocess_text'] = df.Text.apply(preprocess)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dd25c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#        Modelling without Pre-processing Text data using pipeline\n",
    "\n",
    "#  Splitting Data\n",
    "frosparse sklearn.mtrain_test_splitpelinel_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.text,\n",
    "    df.label,\n",
    "    test_size=0.2,\n",
    "    random_state = 2022,\n",
    "    stratify=df.label\n",
    ")\n",
    "\n",
    "\n",
    "#         Modelling with Pre-processing Text data\n",
    "# Splitting Data\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     df.preprocess_text,\n",
    "#     df.label,\n",
    "#     test_size=0.2,\n",
    "#     random_state = 2022,\n",
    "#     stratify=df.label\n",
    "# )\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('count_vector with 1 gram', CountVectorizer() ),\n",
    "    ('model _ multi NB', RandomForestClassifier()),\n",
    "])\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9229e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Observations\n",
    "# As machine learning algorithms do not work on text data directly,\n",
    "# we need to convert them into numeric vectors and feed that into models while training.\n",
    "\n",
    "# In this process, we convert text into a very high dimensional \n",
    "# numeric vector using the technique of Bag of words and we use sklearn CountVectorizer for this.\n",
    "\n",
    "# Without Pre-Processing Data\n",
    "\n",
    "# From the above in most of the cases, we can see that when we have \n",
    "# the count vectorizer above trigrams or at trigrams, the performance\n",
    "# keeps degrading. The major possible reason for this as the ngram_range\n",
    "# keeps increasing, the number of dimensions/features \n",
    "# (possible combination of words) also increases enormously and\n",
    "# models have the risk of overfitting and resulting in terrible performance.\n",
    "\n",
    "# For this reason, models like KNN failed terribly when performed \n",
    "# with trigrams and using the euclidean distance. \n",
    "# K-Nearest Neighbours(KNN) doesn't work well with high-dimensional\n",
    "# data because, with a large number of dimensions, it becomes difficult\n",
    "# for the algorithm to calculate the distance in each dimension. \n",
    "# In higher dimensional space, the cost to calculate distance \n",
    "# becomes expensive and hence impacts the performance of the model. \n",
    "# It performed well for class 1 and had terrible results for Class 0.\n",
    "\n",
    "# Both recall and F1 scores increase better when trained with the\n",
    "# same KNN model but with cosine distance as cosine distance does \n",
    "# not get influenced by the number of dimensions as it uses the \n",
    "# angle better the two text vectors to calculate the similarity.\n",
    "\n",
    "# With respect to Naive and RandomForest models, both performed \n",
    "# really well, and random forest with trigrams has a better edge on the recall metric.\n",
    "\n",
    "# As Random Forest uses Bootstrapping(row and column Sampling)\n",
    "# with many decision trees and overcomes the high variance and \n",
    "# overfitting of high dimensional data and also uses feature \n",
    "# importance of words for better classifying the categories.\n",
    "\n",
    "# The easy calculation of probabilities for the words in the \n",
    "# corpus(Bag of words) and storing them in a contingency table\n",
    "# is the major reason for the Multinomial NaiveBayes to be a\n",
    "# text classification friendly algorithm.\n",
    "\n",
    "\n",
    "# With Pre-Processing Data\n",
    "# Have trained the best model RandomForest on the pre-processed data,\n",
    "# but RandomForest with trigrams fails to produce the same results here.\n",
    "\n",
    "# But the same randomForest with Unigram to Trigram features helps\n",
    "# to produce very amazing results and is tops in the entire list with very good F1 scores and Recall scores.\n",
    "\n",
    "# Machine Learning is like a trial and error scientific method, \n",
    "# where we keep trying all the possible algorithms we have and \n",
    "# select the one which gives good results and satisfies the \n",
    "# requirements like latency, interpretability, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
